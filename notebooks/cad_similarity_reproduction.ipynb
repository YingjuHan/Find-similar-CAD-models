{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Comparing CAD Part Models for Geometrical Similarity (Reproduction)\n",
        "\n",
        "This notebook reproduces the **case-study workflow** of the paper using **synthetic CAD-like parts**. It follows the two-stage similarity approach:\n",
        "1. **Global similarity** via spherical projection and correlation\n",
        "2. **Local similarity** via supervised segmentation + DBSCAN clustering + normal-direction projection\n",
        "\n",
        "Required visualizations: global similarity heatmap, segmentation + DBSCAN clusters, and a ranked retrieval table."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {},
      "execution_count": null,
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "\n",
        "root = Path().resolve()\n",
        "if not (root / \"cad_similarity\").is_dir():\n",
        "    if (root.parent / \"cad_similarity\").is_dir():\n",
        "        root = root.parent\n",
        "    elif (root.parent.parent / \"cad_similarity\").is_dir():\n",
        "        root = root.parent.parent\n",
        "if str(root) not in sys.path:\n",
        "    sys.path.insert(0, str(root))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.neighbors import NearestNeighbors\n",
        "\n",
        "from cad_similarity.synthetic import generate_parts, sample_part\n",
        "from cad_similarity.projection import spherical_projection\n",
        "from cad_similarity.similarity import correlation_similarity, cluster_by_threshold\n",
        "from cad_similarity.segmentation import build_features, train_models\n",
        "from cad_similarity.clustering import dbscan_clusters\n",
        "from cad_similarity.local_similarity import local_similarity\n",
        "\n",
        "np.random.seed(42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate 6 synthetic parts: 3 groups x 2 samples\n",
        "parts = generate_parts(seed=42)\n",
        "[(p.name, p.group) for p in parts]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Sampling + normalization\n",
        "\n",
        "def normalize_points(points):\n",
        "    center = points.mean(axis=0, keepdims=True)\n",
        "    centered = points - center\n",
        "    scale = np.linalg.norm(centered, axis=1).max()\n",
        "    if scale > 0:\n",
        "        centered /= scale\n",
        "    return centered\n",
        "\n",
        "sampled = []\n",
        "for part in parts:\n",
        "    pts, normals, labels = sample_part(part, n_base=1500, n_teeth=600, seed=42)\n",
        "    pts = normalize_points(pts)\n",
        "    norms = np.linalg.norm(normals, axis=1, keepdims=True)\n",
        "    normals = np.divide(normals, norms, out=np.zeros_like(normals), where=norms != 0)\n",
        "    sampled.append({\n",
        "        \"name\": part.name,\n",
        "        \"group\": part.group,\n",
        "        \"points\": pts,\n",
        "        \"normals\": normals,\n",
        "        \"labels\": labels,\n",
        "    })\n",
        "\n",
        "len(sampled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Global spherical projection matrices\n",
        "GLOBAL_BINS = (224, 224)\n",
        "\n",
        "global_mats = [spherical_projection(item[\"points\"], bins=GLOBAL_BINS) for item in sampled]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Global similarity matrix\n",
        "n = len(parts)\n",
        "S = np.zeros((n, n))\n",
        "for i in range(n):\n",
        "    for j in range(n):\n",
        "        S[i, j] = correlation_similarity(global_mats[i], global_mats[j])\n",
        "\n",
        "# Heatmap (required)\n",
        "fig, ax = plt.subplots(figsize=(6, 5))\n",
        "im = ax.imshow(S, cmap=\"viridis\", vmin=-1, vmax=1)\n",
        "ax.set_title(\"Global Similarity (Correlation)\")\n",
        "ax.set_xticks(range(n))\n",
        "ax.set_yticks(range(n))\n",
        "ax.set_xticklabels([p.name for p in parts], rotation=45, ha=\"right\")\n",
        "ax.set_yticklabels([p.name for p in parts])\n",
        "fig.colorbar(im, ax=ax)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Build segmentation dataset\n",
        "X_list, y_list = [], []\n",
        "for item in sampled:\n",
        "    X = build_features(item[\"points\"], item[\"normals\"], k=8)\n",
        "    X_list.append(X)\n",
        "    y_list.append(item[\"labels\"])\n",
        "\n",
        "X_all = np.vstack(X_list)\n",
        "y_all = np.hstack(y_list)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X_all, y_all, test_size=0.25, random_state=42, stratify=y_all\n",
        ")\n",
        "\n",
        "models = train_models(X_train, y_train, seed=42)\n",
        "acc = {name: accuracy_score(y_test, model.predict(X_test)) for name, model in models.items()}\n",
        "acc"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Choose best model for downstream\n",
        "best_name = max(acc, key=acc.get)\n",
        "best_model = models[best_name]\n",
        "print(\"Best model:\", best_name, \"accuracy:\", acc[best_name])\n",
        "\n",
        "# Predict labels for each part\n",
        "for item in sampled:\n",
        "    X = build_features(item[\"points\"], item[\"normals\"], k=8)\n",
        "    item[\"pred_labels\"] = best_model.predict(X)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Segmentation visualization (required)\n",
        "idx = 0\n",
        "item = sampled[idx]\n",
        "pts = item[\"points\"]\n",
        "labels = item[\"pred_labels\"]\n",
        "\n",
        "fig = plt.figure(figsize=(6, 5))\n",
        "ax = fig.add_subplot(111, projection=\"3d\")\n",
        "ax.scatter(pts[labels == 0, 0], pts[labels == 0, 1], pts[labels == 0, 2], s=2, c=\"gray\", alpha=0.5, label=\"base\")\n",
        "ax.scatter(pts[labels == 1, 0], pts[labels == 1, 1], pts[labels == 1, 2], s=4, c=\"red\", alpha=0.8, label=\"teeth\")\n",
        "ax.set_title(f\"Segmentation (part {item['name']})\")\n",
        "ax.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# DBSCAN clustering on predicted teeth (required)\n",
        "item = sampled[idx]\n",
        "mask = item[\"pred_labels\"] == 1\n",
        "teeth_pts = item[\"points\"][mask]\n",
        "\n",
        "if len(teeth_pts) > 10:\n",
        "    nn = NearestNeighbors(n_neighbors=5).fit(teeth_pts)\n",
        "    dists, _ = nn.kneighbors(teeth_pts)\n",
        "    eps = float(dists[:, 1:].mean() * 1.5)\n",
        "else:\n",
        "    eps = 0.05\n",
        "\n",
        "cluster_labels = dbscan_clusters(teeth_pts, eps=eps, min_samples=10)\n",
        "item[\"tooth_clusters\"] = cluster_labels\n",
        "\n",
        "fig = plt.figure(figsize=(6, 5))\n",
        "ax = fig.add_subplot(111, projection=\"3d\")\n",
        "unique = sorted(set(cluster_labels))\n",
        "colors = plt.cm.tab20(np.linspace(0, 1, max(1, len(unique))))\n",
        "for c, col in zip(unique, colors):\n",
        "    idxs = cluster_labels == c\n",
        "    if c == -1:\n",
        "        ax.scatter(teeth_pts[idxs, 0], teeth_pts[idxs, 1], teeth_pts[idxs, 2], s=2, c=\"black\", alpha=0.3, label=\"noise\")\n",
        "    else:\n",
        "        ax.scatter(teeth_pts[idxs, 0], teeth_pts[idxs, 1], teeth_pts[idxs, 2], s=4, color=col, label=f\"cluster {c}\")\n",
        "ax.set_title(f\"DBSCAN clusters (part {item['name']})\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare local similarity matrices for each part\n",
        "local_cluster_mats = []\n",
        "for item in sampled:\n",
        "    mask = item[\"pred_labels\"] == 1\n",
        "    teeth_pts = item[\"points\"][mask]\n",
        "    teeth_normals = item[\"normals\"][mask]\n",
        "\n",
        "    if len(teeth_pts) > 10:\n",
        "        nn = NearestNeighbors(n_neighbors=5).fit(teeth_pts)\n",
        "        dists, _ = nn.kneighbors(teeth_pts)\n",
        "        eps = float(dists[:, 1:].mean() * 1.5)\n",
        "        cluster_labels = dbscan_clusters(teeth_pts, eps=eps, min_samples=10)\n",
        "    else:\n",
        "        cluster_labels = np.array([-1] * len(teeth_pts))\n",
        "\n",
        "    mats = []\n",
        "    for c in sorted(set(cluster_labels)):\n",
        "        if c == -1:\n",
        "            continue\n",
        "        idxs = cluster_labels == c\n",
        "        if idxs.sum() < 10:\n",
        "            continue\n",
        "        mats.append(spherical_projection(teeth_normals[idxs], bins=GLOBAL_BINS))\n",
        "    local_cluster_mats.append(mats)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Ranking example (required)\n",
        "query = 0\n",
        "order = np.argsort(S[query])[::-1]\n",
        "\n",
        "sims_sorted = [S[query, i] for i in order]\n",
        "clusters = cluster_by_threshold(sims_sorted, threshold=0.01)\n",
        "\n",
        "ranking = []\n",
        "for cluster in clusters:\n",
        "    indices = [order[i] for i in cluster]\n",
        "    if len(indices) == 1:\n",
        "        ranking.append(indices[0])\n",
        "    else:\n",
        "        local_scores = {}\n",
        "        for idx2 in indices:\n",
        "            local_scores[idx2] = local_similarity(local_cluster_mats[query], local_cluster_mats[idx2])\n",
        "        indices_sorted = sorted(indices, key=lambda i: local_scores[i], reverse=True)\n",
        "        ranking.extend(indices_sorted)\n",
        "\n",
        "rows = []\n",
        "for rank, idx2 in enumerate(ranking, start=1):\n",
        "    rows.append([\n",
        "        rank,\n",
        "        parts[idx2].name,\n",
        "        parts[idx2].group,\n",
        "        float(S[query, idx2]),\n",
        "        float(local_similarity(local_cluster_mats[query], local_cluster_mats[idx2]))\n",
        "    ])\n",
        "\n",
        "rows[:6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display ranking table\n",
        "fig, ax = plt.subplots(figsize=(7, 2.5))\n",
        "ax.axis('off')\n",
        "col_labels = [\"Rank\", \"Part\", \"Group\", \"GlobalSim\", \"LocalSim\"]\n",
        "cell_text = [[r[0], r[1], r[2], f\"{r[3]:.3f}\", f\"{r[4]:.3f}\"] for r in rows]\n",
        "ax.table(cellText=cell_text, colLabels=col_labels, loc='center')\n",
        "ax.set_title(f\"Retrieval Ranking for Query: {parts[query].name}\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Summary of key parameters\n",
        "params = {\n",
        "    \"global_bins\": GLOBAL_BINS,\n",
        "    \"n_base\": 1500,\n",
        "    \"n_teeth\": 600,\n",
        "    \"cluster_threshold\": 0.01,\n",
        "    \"segmentation_model\": best_name,\n",
        "}\n",
        "params"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}